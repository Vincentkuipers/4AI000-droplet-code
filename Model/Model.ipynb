{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"Solid_droplet\", \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def split_data(DATA_DIR:list, train_frac:float = 0.6, val_frac:float = 0.2, test_frac:float=0.2, use_seed:bool=False, seed:int=42):\n",
    "    \"\"\"Split data into train, validation and test set\"\"\"\n",
    "    if train_frac + val_frac + test_frac != 1:\n",
    "        raise ValueError(\"The sum of train_frac, val_frac and test_frac must be 1\")\n",
    "    \n",
    "    if train_frac>1 or val_frac>1 or test_frac>1:\n",
    "        raise ValueError(\"train_frac, val_frac and test_frac must be less than 1\")\n",
    "    \n",
    "\n",
    "    # Make copy of data_labels\n",
    "    list_of_labels = os.listdir(DATA_DIR).copy()\n",
    "    \n",
    "    # Frac to value\n",
    "    int_val = len(list_of_labels)\n",
    "    train_value = int(train_frac*int_val)\n",
    "    val_value = int(val_frac*int_val)\n",
    "    test_value = int(test_frac*int_val)\n",
    "    del int_val\n",
    "\n",
    "    print(f\"train_value: {train_value}\")\n",
    "    \n",
    "    # Shuffle data\n",
    "    if use_seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    random.shuffle(list_of_labels)\n",
    "\n",
    "    # Split data\n",
    "    train_split = list_of_labels[train_frac*size:]\n",
    "    return train_split\n",
    "    \n",
    "    # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['70_32_1.png', '70_32_1_edgedetection.png']\n"
     ]
    }
   ],
   "source": [
    "list_of_labels = os.listdir(DATA_DIR).copy()\n",
    "random.shuffle(list_of_labels)\n",
    "print(list_of_labels)\n",
    "#data_labels = np.array(os.listdir(DATA_DIR))\n",
    "#random.shuffle(os.listdir(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m split_data(DATA_DIR)\n",
      "Cell \u001b[1;32mIn[118], line 22\u001b[0m, in \u001b[0;36msplit_data\u001b[1;34m(DATA_DIR, train_frac, val_frac, test_frac, use_seed, seed)\u001b[0m\n\u001b[0;32m     19\u001b[0m random\u001b[39m.\u001b[39mshuffle(list_of_labels)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Split data\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m train_split \u001b[39m=\u001b[39m list_of_labels[train_frac\u001b[39m*\u001b[39;49msize:]\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m train_split\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "split_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[39m.\u001b[39;49mlistdir(DATA_DIR)\u001b[39m.\u001b[39;49mto_array()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_array'"
     ]
    }
   ],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, device, dtype) -> None:\n",
    "        \"\"\"Initialisation of the Model class\"\"\"\n",
    "        super().__init__()\n",
    "        self.cnn1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=2, device=device, dtype=dtype)\n",
    "        self.cnn2 = torch.nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2, device=device, dtype=dtype)\n",
    "        self.maxpooling1 = torch.nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.cnn3 = torch.nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=2, device=device, dtype=dtype)\n",
    "        self.cnn4 = torch.nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2, device=device, dtype=dtype)\n",
    "        self.maxpooling2 = torch.nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.lay1 = torch.nn.Linear(3136, 1024, device=device, dtype=dtype).double()\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.lay2 = torch.nn.Linear(1024, 3, device=device, dtype=dtype).double()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model\"\"\"\n",
    "        x1 = self.cnn1(x)\n",
    "        x2 = self.cnn2(x1)\n",
    "        x3 = self.maxpooling1(x2)\n",
    "        x4 = self.cnn3(x3)\n",
    "        x5 = self.cnn4(x4)\n",
    "        x6 = self.maxpooling2(x5)\n",
    "        x7 = self.flatten(x6)\n",
    "        x8 = self.lay1(x7)\n",
    "        x9 = self.activation(x8)\n",
    "        y = self.lay2(x9)\n",
    "        return y[:,0]\n",
    "\n",
    "def saveModel():\n",
    "    path = \"./myFirstModel.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "def train_model (Model, train_loader:list, val_loader:list, epochs:int=50_000, learning_rate:float=0.001):\n",
    "    \"\"\"Training function\"\"\"\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "    model = Model()\n",
    "\n",
    "    #train_losses = []\n",
    "    #val_losses = []\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    #optimizer = torch.optim.Adam(model.parameters()) \n",
    "    #Xtrain, Xval, Ytrain, Yval = [torch.as_tensor(x) for x in [Xtrain, Xval, Ytrain, Yval]] \n",
    "    #for epoch in range(epochs): #a)\n",
    "    #    Loss = torch.mean((model(Xtrain)-Ytrain)**2) \n",
    "    #    optimizer.zero_grad() \n",
    "    #    Loss.backward() \n",
    "    #    optimizer.step() \n",
    "    #    if epoch%1000==0: \n",
    "    #        print(epoch,Loss.item())\n",
    "    #        train_losses.append(Loss.item())\n",
    "    #        val_losses.append(torch.mean((model(Xval)-Yval)**2).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m Model(device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39;49mparameters())\n\u001b[0;32m      3\u001b[0m Loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean((model(Xtrain)\u001b[39m-\u001b[39mYtrain)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "model = Model(device=device, dtype=dtype)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "Loss = torch.mean((model(Xtrain)-Ytrain)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5aua0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
